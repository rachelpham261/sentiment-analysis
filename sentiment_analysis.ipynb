{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data crawling\n",
    "\n",
    "We first crawl movie reviews of Verified Audience on Rotten Tomatoes. These reviews provide star ratings which allow for easy and automatic labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_source(html_source, n=10):\n",
    "    \"\"\"\n",
    "    This function creates a web driver to access a movie review page on rottentomatoes\n",
    "    and performs n clicks on the load more button to load more reviews beyond the display limit.\n",
    "    html_source: str, the url of the movie review page\n",
    "    n: int, the number of times to click the load more button\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the web driver\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(html_source)\n",
    "    driver.implicitly_wait(50)\n",
    "\n",
    "    try:\n",
    "        # Click the load button\n",
    "        clickable = driver.find_element(By.CLASS_NAME, 'load-more-container')\n",
    "        \n",
    "        # Click it n times to load more content\n",
    "        for _ in range(n):\n",
    "            action_chains = ActionChains(driver)\n",
    "            action_chains.click(clickable).perform()\n",
    "            WebDriverWait(driver, 100).until(EC.element_to_be_clickable((By.CLASS_NAME, 'load-more-container')))\n",
    "            time\n",
    "            clickable = driver.find_element(By.CLASS_NAME, 'load-more-container')  # Update clickable element\n",
    "    except NoSuchElementException:\n",
    "        # If no more load-more button is found, stop clicking\n",
    "        pass\n",
    "    \n",
    "    driver.implicitly_wait(2)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(driver):\n",
    "    \"\"\"\n",
    "    This function collects the star ratings and comments from the movie review page given the web driver.\n",
    "    driver: the web driver to the movie review page\n",
    "    \"\"\"\n",
    "    # Find all comments\n",
    "    comment_elements = driver.find_elements(By.CSS_SELECTOR, 'p.audience-reviews__review.js-review-text[data-qa=\"review-text\"]')\n",
    "    comment_texts = [comment.text.strip() for comment in comment_elements]\n",
    "\n",
    "    # Find the star elements and extract the star ratings\n",
    "    html_content = driver.page_source\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    stars = soup.find_all(\"span\", class_=\"audience-reviews__score\")\n",
    "    # ratings = number of full stars + 0.5 * number of half stars\n",
    "    star_ratings = [len(star.find_all(\"span\", class_=\"star-display__filled\")) +\n",
    "                    0.5 * len(star.find_all(\"span\", class_=\"star-display__half\"))\n",
    "                    for star in stars]\n",
    "    \n",
    "    df = pd.DataFrame({\"star\": star_ratings, \"Verfied_Audience_Comment\":comment_texts})\n",
    "    df.reset_index(drop=True , inplace=True)\n",
    "    \n",
    "    driver.quit()\n",
    "    time.sleep(3)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the movie urls stored in a csv file\n",
    "# can crawl more movies by adding more urls to the csv file\n",
    "movie_urls = pd.read_csv(\"Movie_List.csv\")\n",
    "movie_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect reviews and ratings for each movie in the list\n",
    "df_list = []\n",
    "for url in movie_urls['Title']:\n",
    "    try:\n",
    "        driver = data_source(url)\n",
    "        df = collect_data(driver)\n",
    "        print(url, \"success\", f'{df.shape[0]} reviews collected')\n",
    "        df_list.append(df)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.concat(df_list, ignore_index=True)\n",
    "concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label the sentiment of the reviews\n",
    "# stars < 3: negative (-1)\n",
    "# 3 <= stars < 4: neutral (0)\n",
    "# stars >= 4: positive (1)\n",
    "def label_sentiment(df, column):\n",
    "    df['label'] = 0\n",
    "    df.loc[df[column] < 3, 'label'] = -1\n",
    "    df.loc[(3 <= df[column]) & (df['star']< 4), 'label'] = 0\n",
    "    df.loc[df[column] >= 4, 'label'] = 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label the sentiment of the reviews and save the data\n",
    "concat_df = label_sentiment(concat_df, 'star')\n",
    "concat_df.to_csv(\"action_movie.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "We then clean the collected data. The cleaning process involves 3 steps:\n",
    "1. Remove special characters but keep basic punctuation.\n",
    "2. Remove non-english reviews\n",
    "3. Handle missing data (if any) and remove duplicates (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "from langdetect import detect, LangDetectException\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('movie_reviews.csv')\n",
    "\n",
    "# function to remove special characters but keep basic punctuation\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s.,!?]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "# apply the cleaning function\n",
    "data['Verfied_Audience_Comment'] = data['Verfied_Audience_Comment'].apply(clean_text)\n",
    "\n",
    "# function to detect English language\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except LangDetectException:\n",
    "        return False\n",
    "\n",
    "# filter out non-English reviews\n",
    "data = data[data['Verfied_Audience_Comment'].apply(is_english)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star</th>\n",
       "      <th>Verfied_Audience_Comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>a movie that is carried by its two charismatic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.5</td>\n",
       "      <td>if your an action person this is for you. pure...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>wow, how did this get into the movie theaters ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>cool action and story, great summer blockbuster</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>lots of fun dialogand great action. ill gladly...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star                           Verfied_Audience_Comment  label\n",
       "0   3.5  a movie that is carried by its two charismatic...      0\n",
       "1   3.5  if your an action person this is for you. pure...      0\n",
       "2   0.5  wow, how did this get into the movie theaters ...     -1\n",
       "4   4.0    cool action and story, great summer blockbuster      1\n",
       "5   4.0  lots of fun dialogand great action. ill gladly...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert text to lowercase\n",
    "data['Verfied_Audience_Comment'] = data['Verfied_Audience_Comment'].str.lower()\n",
    "\n",
    "# not removing stopwords works better for sentiment analysis\n",
    "# data['Verfied_Audience_Comment'] = data['Verfied_Audience_Comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "# Check for any missing values and drop\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Show cleaned data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9894, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned DataFrame to a CSV file\n",
    "data.to_csv('cleaned_movie_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering with BERT\n",
    "\n",
    "After the data is cleaned, we proceed to vectorize the data to prepare it for training machine learning models. We will use BERT -- a modern embedding method that transforms each sequence of words to a dense, multi-dimensional vector. This vectorized data will then be used to train machine learning models for movie review sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tungnd/miniconda3/envs/bbo-llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from transformers import DistilBertModel, DistilBertTokenizer, BertModel, BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# set seed\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star</th>\n",
       "      <th>Verfied_Audience_Comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>a movie that is carried by its two charismatic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.5</td>\n",
       "      <td>if your an action person this is for you. pure...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>wow, how did this get into the movie theaters ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>cool action and story, great summer blockbuster</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>lots of fun dialogand great action. ill gladly...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star                           Verfied_Audience_Comment  label\n",
       "0   3.5  a movie that is carried by its two charismatic...      0\n",
       "1   3.5  if your an action person this is for you. pure...      0\n",
       "2   0.5  wow, how did this get into the movie theaters ...     -1\n",
       "3   4.0    cool action and story, great summer blockbuster      1\n",
       "4   4.0  lots of fun dialogand great action. ill gladly...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('cleaned_movie_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the DistilBERT model and tokenizer from the transformers library\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# for better performance with the cost of increased runtime, we can use the BERT model instead of the DistilBERT model\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# we tokenize each review into a sequence of word indices in a fixed vocabulary\n",
    "tokenized = df['Verfied_Audience_Comment'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1037, 3185, 2008, 2003]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized[0][:5] # first 5 word indices of the first review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find reviews with length greater than 512\n",
    "skipped_indices = [i for i, x in enumerate(tokenized) if len(x) > 512]\n",
    "len(skipped_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop reviews with length greater than 512\n",
    "tokenized = tokenized.drop(skipped_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BERT model can vectorize multiple reviews at once (called batching) but all reviews must have the same length to pass through the model. Therefore, we pad all reviews to a fixed length with a dummy token (indexed 0 in the vocabulary). To do that, we first find the length of the longest review in the data, and at the same time filter out any review that is longer than what the model can handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0 # the maximum sequence length of the reviews\n",
    "for i, review in enumerate(tokenized.values):\n",
    "    if len(review) > max_len:\n",
    "        max_len = len(review)\n",
    "\n",
    "# pad the sequences to the maximum length\n",
    "padded = np.array([review + [0]*(max_len-len(review)) for i, review in enumerate(tokenized.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9858, 493)\n"
     ]
    }
   ],
   "source": [
    "print (padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum length of reviews is 493."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before padding: [101, 1037, 3185, 2008, 2003, 3344, 2011, 2049, 2048, 23916, 5260, 1010, 1998, 8909, 6935, 3449, 3676, 2004, 2092, 1012, 102]\n",
      "After padding: [  101  1037  3185  2008  2003  3344  2011  2049  2048 23916  5260  1010\n",
      "  1998  8909  6935  3449  3676  2004  2092  1012   102     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0]\n"
     ]
    }
   ],
   "source": [
    "# verify that padding works as expected\n",
    "print ('Before padding:', tokenized[0][:50])\n",
    "print ('After padding:', padded[0][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the padded tokens are dummy, we want the BERT model to ignore these tokens when embedding each review. We do this by masking out these tokens when passing the padded tokenized reviews through the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0) # 0 means ignore\n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "input_ids = torch.tensor(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ids: tensor([  101,  1037,  3185,  2008,  2003,  3344,  2011,  2049,  2048, 23916,\n",
      "         5260,  1010,  1998,  8909,  6935,  3449,  3676,  2004,  2092,  1012,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n"
     ]
    }
   ],
   "source": [
    "print ('Input ids:', input_ids[0][:50])\n",
    "print ('Attention mask:', attention_mask[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [13:31<00:00, 40.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# pass the input ids and attention mask to the model to get the embedding for each review\n",
    "batch_size = 512\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(input_ids), batch_size)):\n",
    "        batch_input_ids = input_ids[i:i+batch_size]\n",
    "        batch_attention_mask = attention_mask[i:i+batch_size]\n",
    "        batch_last_hidden_states = model(batch_input_ids, attention_mask=batch_attention_mask)\n",
    "        embeddings.append(batch_last_hidden_states[0][:,0,:].numpy())\n",
    "embeddings = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9858, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Now we have vectorized the reviews to numpy arrays, we can use standard machine learning algorithms in sklearn to classify each review to one of 3 sentiment labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9858, 9858)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the labels and remove the skipped reviews\n",
    "labels = df['label'].drop(skipped_indices)\n",
    "len(labels), len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of the labels\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(['Negative', 'Neutral', 'Positive'], labels.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that the positive reviews dominate in this dataset, while the neutral reviews are the minority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data to training and testing\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(embeddings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7393, 768), (7393,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2465, 768), (2465,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7935091277890467\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.81      0.77       604\n",
      "           0       0.36      0.19      0.25       299\n",
      "           1       0.86      0.90      0.88      1562\n",
      "\n",
      "    accuracy                           0.79      2465\n",
      "   macro avg       0.65      0.63      0.63      2465\n",
      "weighted avg       0.77      0.79      0.78      2465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Logistic Regression classifier\n",
    "# Setting solver to 'lbfgs' as it can handle multinomial loss for multiclass problems\n",
    "# Increasing 'max_iter' might be necessary for convergence on some datasets\n",
    "lr_clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=5000, random_state=0)\n",
    "\n",
    "# Train the classifier\n",
    "lr_clf.fit(train_features, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = lr_clf.predict(test_features)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "clf_report = classification_report(test_labels, test_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentiment_analysis_model.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to disk\n",
    "import joblib\n",
    "joblib.dump(lr_clf, 'sentiment_analysis_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare the performance of the model with a dummy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6336713995943205\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00       604\n",
      "     Neutral       0.00      0.00      0.00       299\n",
      "    Positive       0.63      1.00      0.78      1562\n",
      "\n",
      "    accuracy                           0.63      2465\n",
      "   macro avg       0.21      0.33      0.26      2465\n",
      "weighted avg       0.40      0.63      0.49      2465\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tungnd/miniconda3/envs/bbo-llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tungnd/miniconda3/envs/bbo-llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tungnd/miniconda3/envs/bbo-llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier()\n",
    "\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "dummy_test_predictions = clf.predict(test_features)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(test_labels, dummy_test_predictions)\n",
    "dummy_clf_report = classification_report(test_labels, dummy_test_predictions, target_names=['Negative', 'Neutral', 'Positive'])\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(dummy_clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model performs significantly better than the dummy model. However, it can also be seen that the model performs poorty w.r.t. negative and neutral reviews, which have less data points in the dataset compared to the positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=5000, multi_class=&#x27;multinomial&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=5000, multi_class=&#x27;multinomial&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=5000, multi_class='multinomial', random_state=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # assert detect(text) == 'en', 'Text is not in English'\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s.,!?]', '', text)\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    # cleaned_text = ' '.join([word for word in cleaned_text.split() if word not in (stop)])\n",
    "    return cleaned_text\n",
    "\n",
    "def get_embeddings(sample_comments, model, tokenizer):\n",
    "    sample_comments = [clean_text(comment) for comment in sample_comments]\n",
    "    tokenized = [tokenizer.encode(comment, add_special_tokens=True) for comment in sample_comments]\n",
    "    \n",
    "    # pad to max length\n",
    "    max_len = 0 # the maximum sequence length of the reviews\n",
    "    for i, review in enumerate(tokenized):\n",
    "        if len(review) > max_len:\n",
    "            max_len = len(review)\n",
    "\n",
    "    # pad the sequences to the maximum length\n",
    "    padded = np.array([review + [0]*(max_len-len(review)) for i, review in enumerate(tokenized)])\n",
    "    \n",
    "    # get attn mask\n",
    "    attention_mask = np.where(padded != 0, 1, 0) # 0 means ignore\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "    input_ids = torch.tensor(padded)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "    embeddings = last_hidden_states[0][:,0,:].numpy()\n",
    "    return embeddings\n",
    "\n",
    "def pipeline(comments):\n",
    "    embeddings = get_embeddings(comments, model, tokenizer)\n",
    "    predictions = lr_clf.predict(embeddings)\n",
    "    sentiment_map = {-1: 'Negative', 1: 'Positive', 0: 'Neutral'}\n",
    "    predictions = [sentiment_map[pred] for pred in predictions]\n",
    "    prediction_df = pd.DataFrame({'comment': comments, 'sentiment': predictions})\n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_comments = [\n",
    "    \"I didn't think they'd be able to top the first one but goddammit they pulled it off.  This is immediately my new favorite Spider-Man movie\",\n",
    "    \"Who knew movies about the multiverse were so fascinated with bagels?\",\n",
    "    \"Cool twist at the end when Miles Morales met his evil alt-universe twin Miles NoMorales\",\n",
    "    \"Damn not as good as the first.\",\n",
    "    \"Anyone else not love it?\",\n",
    "    \"That ending was one of the biggest movie mistakes I can think of. What were they thinking?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I didn't think they'd be able to top the first...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who knew movies about the multiverse were so f...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cool twist at the end when Miles Morales met h...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Damn not as good as the first.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anyone else not love it?</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>That ending was one of the biggest movie mista...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment sentiment\n",
       "0  I didn't think they'd be able to top the first...  Positive\n",
       "1  Who knew movies about the multiverse were so f...  Positive\n",
       "2  Cool twist at the end when Miles Morales met h...  Positive\n",
       "3                     Damn not as good as the first.  Negative\n",
       "4                           Anyone else not love it?  Negative\n",
       "5  That ending was one of the biggest movie mista...  Negative"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(sample_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbo-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
