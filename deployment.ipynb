{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "from langdetect import detect\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from transformers import DistilBertModel, DistilBertTokenizer, BertModel, BertTokenizer\n",
    "import joblib\n",
    "\n",
    "# set seed\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # assert detect(text) == 'en', 'Text is not in English'\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s.,!?]', '', text)\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    cleaned_text = ' '.join([word for word in cleaned_text.split() if word not in (stop)])\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(sample_comments, model, tokenizer):\n",
    "    sample_comments = [clean_text(comment) for comment in sample_comments]\n",
    "    tokenized = [tokenizer.encode(comment, add_special_tokens=True) for comment in sample_comments]\n",
    "    \n",
    "    # pad to max length\n",
    "    max_len = 0 # the maximum sequence length of the reviews\n",
    "    for i, review in enumerate(tokenized):\n",
    "        if len(review) > max_len:\n",
    "            max_len = len(review)\n",
    "\n",
    "    # pad the sequences to the maximum length\n",
    "    padded = np.array([review + [0]*(max_len-len(review)) for i, review in enumerate(tokenized)])\n",
    "    \n",
    "    # get attn mask\n",
    "    attention_mask = np.where(padded != 0, 1, 0) # 0 means ignore\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "    input_ids = torch.tensor(padded)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "    embeddings = last_hidden_states[0][:,0,:].numpy()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(comments, model_path):\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "    embeddings = get_embeddings(comments, model, tokenizer)\n",
    "    model = joblib.load(model_path)\n",
    "    predictions = model.predict(embeddings)\n",
    "    sentiment_map = {-1: 'Negative', 1: 'Positive', 0: 'Neutral'}\n",
    "    predictions = [sentiment_map[pred] for pred in predictions]\n",
    "    prediction_df = pd.DataFrame({'comment': comments, 'sentiment': predictions})\n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_comments = [\n",
    "    # \"I didn't think they'd be able to top the first one but goddammit they pulled it off.  This is immediately my new favorite Spider-Man movie\",\n",
    "    # \"Who knew movies about the multiverse were so fascinated with bagels?\",\n",
    "    # \"I absolutely loved it! Only thing is, I don’t know if it was just how they had the sound at my theater or if it was the sound mixing in the movie, but there were a lot of moments where the soundtrack was booming and the dialogue got lost and I couldn’t hear what they were saying. Like even Gwen’s opening monologue I could barely hear. I almost wished I had closed captioning. Was it like this for anyone else or was it just the speakers in my theater? My husband and I might try to watch in a different theater\",\n",
    "    # \"That might have been the best first half of an animated movie I’ve ever seen\",\n",
    "    # \"Cool twist at the end when Miles Morales met his evil alt-universe twin Miles NoMorales\",\n",
    "    \"I did not like the movie.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I did not like the movie.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     comment sentiment\n",
       "0  I did not like the movie.  Positive"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(sample_comments, model_path='sentiment_analysis_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbo-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
